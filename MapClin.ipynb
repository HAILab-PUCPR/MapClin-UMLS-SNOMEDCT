{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MapClin 24/01/22\n",
    "#Necessario 4GB de RAM livres (computador com 8GB sem mais nada rodando)\n",
    "\n",
    "#!pip install click==7.0\n",
    "#!pip install Exit\n",
    "#!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
    "##import sys\n",
    "##!{sys.executable} -m conda install -c conda-forge spacy-model-pt_core_news_sm\n",
    "#!pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import unidecode\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "#!pip install snowballstemmer\n",
    "import snowballstemmer\n",
    "import stanza\n",
    "#stanza.download('pt')\n",
    "from dicio import Dicio\n",
    "#https://github.com/felipemfp/dicio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import collections\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_dublicates(X):\n",
    "    unique_X = []\n",
    "    for i, row in enumerate(X):\n",
    "        if row not in X[i + 1:]:\n",
    "            unique_X.append(row)\n",
    "    return unique_X\n",
    "\n",
    "def levenshtein(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "class FileManager:\n",
    "    def open_xlsx_folder(self, folder_path):\n",
    "        '''\n",
    "        Leitura de arquivos xlsx (le todos os arquivos em uma pasta)\n",
    "        Necessário fornecer o caminho da pasta\n",
    "        '''\n",
    "        paths = glob.glob(folder_path +\"/*.xlsx\")\n",
    "        data = pd.DataFrame()   \n",
    "        for path in paths:\n",
    "            df = pd.read_excel(path)\n",
    "            print('Path: ',path,'\\nLen: ',len(df),'\\n')\n",
    "            data = data.append(df)\n",
    "        data.reset_index(inplace = True)\n",
    "        return data\n",
    "    \n",
    "    def open_xlsx(self, path):\n",
    "        '''\n",
    "        Leitura arquivo xlsx\n",
    "        '''\n",
    "        df = pd.read_excel(path)\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def open_txt(self, path, header):\n",
    "        '''\n",
    "        Leitura arquivo txt\n",
    "        '''\n",
    "        if header == True:\n",
    "            df = pd.read_csv(path, delimiter = '\\n')\n",
    "        else:\n",
    "            df = pd.read_csv(path, delimiter = '\\n', header = None)\n",
    "    \n",
    "        return df\n",
    "\n",
    "\n",
    "class PreProcessamento:\n",
    "    #def __init__(self):\n",
    "    #    self.lemmatizer = nltk.WordNetLemmatizer()\n",
    "    #    self.nlp = stanza.Pipeline('pt', processors='tokenize,mwt,pos,lemma', tokenize_pretokenized=True)\n",
    "    \n",
    "    __instance = None\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def getInstance(cls):\n",
    "        if not cls.__instance:\n",
    "            cls.__instance = PreProcessamento()\n",
    "            cls.__instance.lemmatizer = nltk.WordNetLemmatizer()\n",
    "            cls.__instance.nlp = stanza.Pipeline('pt', processors='tokenize,mwt,pos,lemma', tokenize_pretokenized=True)\n",
    "        return cls.__instance\n",
    "           \n",
    "    \n",
    "    \n",
    "    def separaTextoEmSentenças(self,texto): # NÂO tokenizado\n",
    "        sent_tokenizer = nltk.data.load('tokenizers/punkt/portuguese.pickle')\n",
    "        return sent_tokenizer.tokenize(texto)\n",
    "    \n",
    "    def tokeniza(self,sentenca): # NÂO tokenizado\n",
    "        #return self.tokenizer.tokenize(texto)\n",
    "        return nltk.tokenize.word_tokenize(sentenca, language='portuguese')\n",
    "        \n",
    "    def expandeAcronimo(self,texto): #tokenizado\n",
    "        #quanto acronimo esta em minusculo ele não é expandido, \n",
    "        #porém colocar tudo para upper case faz com que não acronimos sejam expandidos, levando a erros! (como \"da\")\n",
    "        import pickle\n",
    "        acronimosDict = pickle.load(open(\"DefaultAcronyms.pkl\", \"rb\"))\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            if token in acronimosDict:\n",
    "                expandido = self.tokeniza(acronimosDict[token])\n",
    "                newTexto.extend(expandido)\n",
    "            else:\n",
    "                newTexto.append(token)\n",
    "        return newTexto\n",
    "    \n",
    "    def removeALLspace(self,string): # NÂO tokenizado\n",
    "        ns = \"\"\n",
    "        for s in string:\n",
    "            if s != \" \":\n",
    "                ns+=s\n",
    "        return ns\n",
    "    \n",
    "    def normalizaAcento(self,text): # NÂO tokenizado    \n",
    "        try:\n",
    "            text = unicode(text, 'utf-8')\n",
    "        except NameError: # unicode is a default on python 3 \n",
    "            pass\n",
    "    \n",
    "        text = unicodedata.normalize('NFD', text)\\\n",
    "               .encode('ascii', 'ignore')\\\n",
    "               .decode(\"utf-8\")\n",
    "\n",
    "        novo_s = re.sub(\"Ã…|Ã€|Ã |Ãƒ|Ã‚|Ã„\",\"A\",text);\n",
    "        novo_s=re.sub(\"Ã¥|Ã |Ã¡|Ã£|Ã¢|Ã¤\",\"a\",novo_s);\n",
    "        novo_s=re.sub(\"Ã¨|Ã©|Ã«|Ãª\",\"e\",novo_s);\n",
    "        novo_s=re.sub(\"Ãˆ|Ã‰|Ã‹|ÃŠ\",\"E\",novo_s);\n",
    "        novo_s=re.sub(\"Ã¬|Ã­|Ã¯|Ã®\",\"i\",novo_s);\n",
    "        novo_s=re.sub(\"ÃŒ|Ã |Ã |ÃŽ]\",\"I\",novo_s);\n",
    "        novo_s=re.sub(\"Ã²|Ã³|Ã¶|Ã´|Ãµ\",\"o\",novo_s);\n",
    "        novo_s=re.sub(\"Ã'|Ã\\\"|Ã-|Ã•\",\"O\",novo_s);\n",
    "        novo_s=re.sub(\"Ã¹|Ãº|Ã¼|Ã»/\",\"u\",novo_s);\n",
    "        novo_s=re.sub(\"Ã™|Ãš|Ãœ|Ã›/\",\"U\",novo_s);\n",
    "        novo_s=re.sub(\"Ã½|Ã¿\",\"y\",novo_s);\n",
    "        novo_s=re.sub(\"Ã |Å¸\",\"Y\",novo_s);\n",
    "        novo_s=re.sub(\"Ã§\",\"c\",novo_s);\n",
    "        novo_s=re.sub(\"Ã‡\",\"C\",novo_s);\n",
    "        \n",
    "        return str(text)\n",
    "    \n",
    "    def normalizaAcentoERemoveCaracterEspecial(self,texto): #tokenizado\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            newToken = ''.join(e for e in unidecode.unidecode(token) if e.isalnum())\n",
    "            if len(newToken) != 0:\n",
    "                newTexto.append(newToken)\n",
    "        return newTexto        \n",
    "        \n",
    "    def removeCaracteresNaoAlfabeticos(self,string): # NÃO tokenizado\n",
    "        return re.sub(\"[^A-Za-z']+\", ' ', string)\n",
    "    \n",
    "    def removeCaracteresNaoAlfabeticos(self,texto): # tokenizado\n",
    "        # remove punctuations\n",
    "        remove = string.punctuation \n",
    "        texto = [''.join(c for c in s if c not in remove) for s in texto]\n",
    "        return texto\n",
    "        \n",
    "    def removeEspacoVazioAntesDepoisSTR(self, string): #NÃO tokenizado\n",
    "        return string.strip()\n",
    "        \n",
    "    def removeEspacoVazioAntesDepoisTOKENIZED(self, texto): #tokenizado\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            newTexto.append(self.removeEspacoVazioAntesDepoisSTR(token))\n",
    "        return newTexto    \n",
    "    \n",
    "    def normalizaPontuacao(self, texto:str) -> str: #NÃO tokenizado\n",
    "        '''Makes basic punctuation normalizations.'''\n",
    "\n",
    "        #normalize punctuation\n",
    "        texto=re.sub('>=',\" maior igual a \",texto)\n",
    "        texto=re.sub('<=',\" menor igual a \",texto)\n",
    "        texto=re.sub(';',' ; ',texto)\n",
    "        texto=re.sub('>>','~~~',texto)\n",
    "        texto=re.sub('<<','°°°',texto)\n",
    "        texto=re.sub('>',' maior que ',texto)\n",
    "        texto=re.sub('<',' menor que ',texto)\n",
    "        texto=re.sub('~~~','>>',texto)\n",
    "        texto=re.sub('°°°','<<',texto)\n",
    "        texto=re.sub('=', ' = ',texto)\n",
    "        texto=re.sub('\\:',' : ',texto)\n",
    "        texto=re.sub('\\[', ' [ ', texto)\n",
    "        texto=re.sub('\\]', ' ] ',texto)\n",
    "        texto=re.sub('\\(', ' ( ',texto)\n",
    "        texto=re.sub('\\)', ' ) ',texto)\n",
    "        return texto\n",
    "           \n",
    "    def normalizaMedidas(self, text:str) -> str: #NÃO tokenizado\n",
    "        '''Makes basic number and physics grandeur normalization.'''\n",
    "        \n",
    "        #protect the decimal's '.' from the period normalization\n",
    "        times = re.findall('\\d+x\\/\\w+',text)\n",
    "        for time in times:\n",
    "            t = re.search('(\\d+x)\\/(\\w+)', time)\n",
    "            text = re.sub(t.group(1) + '\\/' + t.group(2), t.group(1) + ' por ' + t.group(2), text)\n",
    "\n",
    "        #protect the decimal's '.' from the period normalization\n",
    "        decimals = re.findall('\\d+\\.\\d+',text)\n",
    "        for decimal in decimals:\n",
    "            d = re.search('(\\d+)\\.(\\d+)', decimal)\n",
    "            text = re.sub(d.group(1) + '\\.' + d.group(2), d.group(1) + 'SINALDECIMAL' + d.group(2), text)\n",
    "\n",
    "        #protect the decimal's ',' from the comma normalization\n",
    "        decimals = re.findall('\\d+\\,\\d+',text)\n",
    "        for decimal in decimals:\n",
    "            d = re.search('(\\d+)\\,(\\d+)', decimal)\n",
    "            text = re.sub(d.group(1) + '\\,' + d.group(2), d.group(1) + 'SINALVIRGULA' + d.group(2), text)\n",
    "\n",
    "        #normalize gaps\n",
    "        gaps=re.findall('\\d-\\d',text)\n",
    "        for gap in gaps:\n",
    "            g=re.search('(\\d)-(\\d)',gap)\n",
    "            text=re.sub(g.group(1)+'-'+g.group(2),g.group(1)+' - '+g.group(2),text)\n",
    "\n",
    "        #normalize periods\n",
    "        periods = re.findall('\\w\\.\\s?',text)\n",
    "        for period in periods:\n",
    "            p=re.search('(\\w)\\.\\s?',period)\n",
    "            text=re.sub(p.group(1)+'\\.',p.group(1)+' . ',text)\n",
    "\n",
    "        #normalize commas\n",
    "        text=re.sub(',',' , ',text)\n",
    "\n",
    "        #return the decimal's '.'\n",
    "        text=re.sub('SINALDECIMAL','.',text)\n",
    "        text=re.sub('SINALVIRGULA',',',text)\n",
    "        \n",
    "        word2trig =    {'milimetros':'mm','milímetros':'mm','milímetro':'mm','milimetro':'mm','centimetros':'cm','centímetros':'cm','centímetro':'cm','centimetro':'cm','decimetros':'dc','decímetros':'dc','decímetro':'dc','decimetro':'dc','metros':'m','metro':'m','decametros':'dam','decâmetros':'dam','decametro':'dam','decâmetro':'dam','quilometros':'km','quilômetros':'km','quilômetro':'km','quilometro':'km','milisegundos':'ms','milisegundo':'ms','segundos':'s','segundo':'s','minutos':'min','minuto':'min','horas':'h','hora':'h','miligramas':'mg','miligrama':'mg','gramas':'g','grama':'g','quilogramas':'kg','quilos':'kg','quilo':'kg','quilograma':'kg','mililitros':'ml','mililitro':'ml','litros':'l','litro':'l'}\n",
    "        \n",
    "        #normalize physics grandeurs\n",
    "        for word in word2trig:\n",
    "            change = word2trig[word]\n",
    "            pattern = f'(\\s{word}\\s)'\n",
    "            text = re.sub(pattern, ' '+change+' ', text)\n",
    "        \n",
    "        word2number =  {'um':'1','dois':'2','duas':'2','três':'3','quatro':'4','cinco':'5','seis':'6','sete':'7','oito':'8','nove':'9','dez':'10','onze':'11','doze':'12','treze':'13','quatorze':'14','quinze':'15','dezesseis':'16','dezessete':'17','dezoito':'18','dezenove':'19','vinte':'20','trinta':'30','quarenta':'40','cinquenta':'50','sessenta':'60','setenta':'70','oitenta':'80','noventa':'90','cem':'100','cento':'100','duzentos':'200','trezentos':'300','quatrocentos':'400','quinhentos':'500','seiscentos':'600','setecentos':'700','oitocentos':'800','novecentos':'900','mil':'1000','milhão':'1000000'}\n",
    "        \n",
    "        triggers = ['mm', 'cm', 'dm', 'm', 'dam', 'hm', 'km', 'ms', 's',\n",
    "                    'min', 'h', 'hs', 'mg', 'ng', 'g', 'kg', 'ml', 'l',\n",
    "                    'anos', 'ano', 'mês', 'mes', 'meses', 'dia', 'dias',\n",
    "                    'mol', 'nmol', 'mmol', 'umol']\n",
    "        \n",
    "        #normalize numbers\n",
    "        for word in word2number:\n",
    "            change = word2number[word]\n",
    "            if word != 'um':\n",
    "                pattern = f'(\\s{word}\\s)'\n",
    "                text = re.sub(pattern, ' '+change+' ', text)\n",
    "            else:\n",
    "                for t in triggers:\n",
    "                    pattern = f'(\\s{word}\\s(?={t}\\s))'\n",
    "                    text = re.sub(pattern, ' '+change+' ', text)  \n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def normalizaMinusculo(self,texto): #tokenizado\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            newTexto.append(token.lower())\n",
    "        return newTexto\n",
    "    \n",
    "    def removeStopWords1(self,texto): #tokenizado\n",
    "        #usado por Lucas Ronnau\n",
    "        stopWordsList = ['de', 'do', 'dos', 'da', 'das', 'uma', 'quem', 'por', 'o', 'as', 'a', 'as', 'com', 'para', 'seu', 'uns', 'umas', 'e', 'ou', 'pra', 'na', 'nas', 'no', 'pelo', 'como', 'sua', 'nos', 'ao', 'aos', 'em', 'que', 'um', 'pela']\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            if token not in stopWordsList:\n",
    "                newTexto.append(token)\n",
    "        return newTexto\n",
    "    \n",
    "    def removeStopWords2(self,texto): #tokenizado\n",
    "        # stop words do nltk\n",
    "        stopWordsList = set(stopwords.words('portuguese'))\n",
    "        stopWordsList.remove('não')\n",
    "        newTexto = []\n",
    "        for token in texto:\n",
    "            if token not in stopWordsList:\n",
    "                newTexto.append(token)\n",
    "        return newTexto\n",
    "\n",
    "    def destokeniza(self,texto):\n",
    "        a = \"\"\n",
    "        for token in texto:\n",
    "            a += \" \" + token.replace(\" \", \"-\")\n",
    "        return a[1:]\n",
    "    \n",
    "    def spacyPipeNormalization(self,textos): #mais que um texto #alterado de Giovanni\n",
    "        import spacy #será chamado uma vez, então tudo bem importar aqui\n",
    "        nlp = spacy.load('pt_core_news_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "        newTexts = []\n",
    "        for doc in nlp.pipe(texto, batch_size=5000, n_threads=-1):\n",
    "            newTexts.append([token.lemma_ for token in doc if not token.is_stop])\n",
    "        return newTexts\n",
    "    \n",
    "    def stemmer(self,text):  # NÃO tokenizado\n",
    "        stemmer = snowballstemmer.stemmer('portuguese')\n",
    "        return ' '.join(stemmer.stemWords(text.split())).strip()\n",
    "\n",
    "    def lematizador(self,text):  # tokenizado\n",
    "        lemma = []\n",
    "        try:\n",
    "            for sent in self.nlp([text]).sentences:\n",
    "                for word in sent.words:\n",
    "                    lemma.append(word.lemma)\n",
    "        except:\n",
    "            pass\n",
    "        return lemma\n",
    "    \n",
    "    def processa(self,texto):\n",
    "        #texto = self.removeALLspace(texto)\n",
    "        #texto = self.removeCaracteresNaoAlfabeticos(texto)\n",
    "        texto = self.normalizaAcento(texto)\n",
    "        texto = self.normalizaPontuacao(texto)\n",
    "        texto = self.normalizaMedidas(texto)\n",
    "            \n",
    "        texto = self.tokeniza(texto)\n",
    "\n",
    "        texto = self.removeEspacoVazioAntesDepoisTOKENIZED(texto)\n",
    "        texto = self.expandeAcronimo(texto)\n",
    "        texto = self.normalizaAcentoERemoveCaracterEspecial(texto) #função de normalizar acento mais simples que \"removeAcento\"\n",
    "        texto = self.normalizaMinusculo(texto)\n",
    "        texto = self.removeStopWords2(texto)\n",
    "        #texto = self.lematizador(texto)\n",
    "        \n",
    "        texto = self.destokeniza(texto)\n",
    "        \n",
    "        texto = self.stemmer(texto)\n",
    "            \n",
    "        texto = self.tokeniza(texto)\n",
    "\n",
    "        return texto\n",
    "               \n",
    "    def normalizaMAPCLIN(self,texto):\n",
    "        texto = self.normalizaAcentoERemoveCaracterEspecial(texto)\n",
    "        texto = self.normalizaMinusculo(texto)\n",
    "        texto = self.removeStopWords1(texto)\n",
    "        return texto\n",
    "    \n",
    "    def processaMAPCLIN(self,texto):\n",
    "        if type(texto) == str:\n",
    "            texto = self.tokeniza(texto)\n",
    "        texto = self.expandeAcronimo(texto)\n",
    "        texto = self.normalizaMAPCLIN(texto)\n",
    "        return texto\n",
    "    \n",
    "\n",
    "#PreProcessamento.getInstance().processa(\"éstAvÃ§ andava na UTI Ontem? (2 > quatro miligrama!\")\n",
    "\n",
    "\n",
    "#puxar classe para cima\n",
    "class UMLSclass:\n",
    "    def __init__(self,preProcessamentoclass):\n",
    "        self.preProcessamento = preProcessamentoclass\n",
    "    \n",
    "    def selectUMLS(self,dadosUMLS):\n",
    "        MRCONSO = dadosUMLS[0]\n",
    "        MRXW_POR = dadosUMLS[1]\n",
    "        MRREL = dadosUMLS[2]\n",
    "        \n",
    "        newMRCONSO = []\n",
    "        for linha in MRCONSO:\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termoProcessado = self.preProcessamento.processaMAPCLIN(termo)\n",
    "            termoSTR = self.preProcessamento.destokeniza(termoProcessado)\n",
    "            newMRCONSO.append((linha[0],linha[1],termoProcessado,termoSTR,termo))\n",
    "            \n",
    "        newMRXW_POR = []\n",
    "        for linha in MRXW_POR:\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termoProcessado = self.preProcessamento.processaMAPCLIN(termo)            \n",
    "            termoSTR = self.preProcessamento.destokeniza(termoProcessado)\n",
    "            newMRXW_POR.append((linha[0],linha[1],termoProcessado,termoSTR,termo))\n",
    "            \n",
    "        return newMRCONSO,newMRXW_POR,MRREL #retornar somente as listas de termos\n",
    "    \n",
    "    def stemmUMLS(self,UMLSnormalizada):\n",
    "        #add stem column\n",
    "        MRCONSO = UMLSnormalizada[0]\n",
    "        MRXW_POR = UMLSnormalizada[1]\n",
    "        MRREL = UMLSnormalizada[2]\n",
    "        \n",
    "        newMRCONSO = []\n",
    "        for linha in MRCONSO:\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termo = self.preProcessamento.destokeniza(termo)\n",
    "            termoSTEMM = self.preProcessamento.stemmer(termo) #precisa ser string\n",
    "            #linha[posicao] = termoProcessado\n",
    "            newMRCONSO.append((linha[0],linha[1],linha[2],linha[3],linha[4],termoSTEMM))\n",
    "            \n",
    "        newMRXW_POR = []\n",
    "        for linha in MRXW_POR:\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termo = self.preProcessamento.destokeniza(termo)\n",
    "            termoSTEMM = self.preProcessamento.stemmer(termo) #precisa ser string\n",
    "            #linha[posicao] = termoProcessado\n",
    "            newMRXW_POR.append((linha[0],linha[1],linha[2],linha[3],linha[4],termoSTEMM))\n",
    "            \n",
    "        return newMRCONSO,newMRXW_POR,MRREL #retornar somente as listas de termos        \n",
    "        \n",
    "    def lematizaUMLS(self,UMLSnormalizada):\n",
    "        #add lemma column\n",
    "        MRCONSO = UMLSnormalizada[0]\n",
    "        MRXW_POR = UMLSnormalizada[1]\n",
    "        MRREL = UMLSnormalizada[2]\n",
    "        \n",
    "        newMRCONSO = []\n",
    "        ci = 0\n",
    "        print(len(MRCONSO)+len(MRXW_POR))\n",
    "        for linha in MRCONSO:\n",
    "            print(ci,end=\"\\r\")\n",
    "            ci=ci+1\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termoLEMMA = self.preProcessamento.lematizador(termo) \n",
    "            #linha[posicao] = termoProcessado\n",
    "            newMRCONSO.append((linha[0],linha[1],linha[2],linha[3],linha[4],linha[5],termoLEMMA))\n",
    "            \n",
    "        newMRXW_POR = []\n",
    "        for linha in MRXW_POR:\n",
    "            print(ci,end=\"\\r\")\n",
    "            ci=ci+1\n",
    "            #pega coluna com termos\n",
    "            posicao = 2 #PRECISA PEGAR POSICAO\n",
    "            termo = linha[posicao]\n",
    "            termoLEMMA = self.preProcessamento.lematizador(termo) \n",
    "            #linha[posicao] = termoProcessado\n",
    "            newMRXW_POR.append((linha[0],linha[1],linha[2],linha[3],linha[4],linha[5],termoLEMMA))\n",
    "            \n",
    "        return newMRCONSO,newMRXW_POR,MRREL #retornar somente as listas de termos        \n",
    "        \n",
    "    \n",
    "    def openFiles(self,files):\n",
    "        MRCONSOFILE = UMLSfiles[0]\n",
    "        MRXW_PORFILE = UMLSfiles[1]\n",
    "        MRRELFILE = UMLSfiles[2]\n",
    "        \n",
    "        ############################################\n",
    "\n",
    "        f = open(MRXW_PORFILE, \"r\")\n",
    "        MRXW_PORRAW = f.read().split(\"\\n\")\n",
    "        del MRXW_PORRAW[-1] #ultima linha é vazia\n",
    "        f.close()\n",
    "        ##print(len(MRXW_PORRAW)) #1589110\n",
    "        ##print(MRXW_PORRAW[123400]) #'POR|amostra|C0550117|L12632755|S15615562|'\n",
    "        \n",
    "        MRXW_POR = []\n",
    "        for y,linha in enumerate(MRXW_PORRAW):\n",
    "            linhaSeparada =  linha.split(\"|\")\n",
    "            CUI = linhaSeparada[2]\n",
    "            WD  = linhaSeparada[1]\n",
    "            MRXW_POR.append((y,CUI,WD)) #cui, word in lower case\n",
    "\n",
    "        ############################################\n",
    "\n",
    "        with open(MRCONSOFILE, \"r\", encoding=\"utf8\") as MRCONSORAW:\n",
    "            # C0003803|SPA|S|L3401341|PF|S3928999|Y|A9197782||M0001704|D001139|\n",
    "            # MSHSPA|MH|D001139|Malformación de Arnold-Chiari|3|N||\n",
    "            # len = 425742\n",
    "            MRCONSO = []\n",
    "            for y,linha in enumerate(MRCONSORAW):\n",
    "                linhaSeparada =  linha.split(\"|\")\n",
    "                CUI = linhaSeparada[0]\n",
    "                STR  = linhaSeparada[14]\n",
    "                LAT  = linhaSeparada[1]\n",
    "                if LAT == \"POR\":\n",
    "                    MRCONSO.append((y,CUI,STR))\n",
    "                    \n",
    "        ############################################\n",
    "\n",
    "        with open(MRRELFILE, \"r\", encoding=\"utf8\") as MRRELRAW:\n",
    "            # C0851745|A31370316|SDUI|CHD|C0003466|A31264097|SDUI||R191307594||MDRKOR||||N||\n",
    "    \n",
    "            MRREL = []\n",
    "            for y,linha in enumerate(MRRELRAW):\n",
    "                linhaSeparada =  linha.split(\"|\")\n",
    "                CUI1 = linhaSeparada[0]\n",
    "                CUI2  = linhaSeparada[4]\n",
    "                REL = linhaSeparada[3]\n",
    "                if REL == \"SY\" and CUI1 != CUI2:\n",
    "                    MRREL.append((y,CUI1,CUI2))\n",
    "                    \n",
    "        \n",
    "        return MRCONSO,MRXW_POR,MRREL\n",
    "    \n",
    "    def openFilesUMLStoSNOMED(self,MRCONSOFILE,MRRELFILE):\n",
    "    \n",
    "        with open(MRCONSOFILE, \"r\", encoding=\"utf8\") as MRCONSORAW:\n",
    "            # C0003803|SPA|S|L3401341|PF|S3928999|Y|A9197782||M0001704|D001139|\n",
    "            # MSHSPA|MH|D001139|Malformación de Arnold-Chiari|3|N||\n",
    "            # len = 425742\n",
    "            snomed = []\n",
    "            for y,linha in enumerate(MRCONSORAW):\n",
    "                linhaSeparada =  linha.split(\"|\")\n",
    "                CUI  = linhaSeparada[0]\n",
    "                STT  = linhaSeparada[4]\n",
    "                ISPREF = linhaSeparada[6]\n",
    "                SAB  = linhaSeparada[11]\n",
    "                TTY  = linhaSeparada[12]\n",
    "                CODE = linhaSeparada[13]          \n",
    "                STR  = linhaSeparada[14]\n",
    "                if SAB == \"SNOMEDCT_US\":\n",
    "                    snomed.append((y,CODE,STR,CUI,TTY,ISPREF,STT))\n",
    "                    \n",
    "        ############################################\n",
    "    \n",
    "        with open(MRRELFILE, \"r\", encoding=\"utf8\") as MRRELRAW:\n",
    "            # C0851745|A31370316|SDUI|CHD|C0003466|A31264097|SDUI||R191307594||MDRKOR||||N||\n",
    "        \n",
    "            SY = []\n",
    "            REL_SNOMED = []\n",
    "            for y,linha in enumerate(MRRELRAW):\n",
    "                linhaSeparada =  linha.split(\"|\")\n",
    "                CUI1 = linhaSeparada[0]\n",
    "                REL  = linhaSeparada[3]\n",
    "                CUI2 = linhaSeparada[4]\n",
    "                RELA = linhaSeparada[7]\n",
    "                SAB  = linhaSeparada[10]\n",
    "                if CUI1 != CUI2:\n",
    "                    if REL == \"SY\":\n",
    "                        SY.append((y,CUI1,CUI2,SAB,REL,RELA))\n",
    "                    if SAB == \"SNOMEDCT_US\":\n",
    "                        REL_SNOMED.append((y,CUI1,CUI2,SAB,REL,RELA))\n",
    "        \n",
    "        return snomed,SY,REL_SNOMED\n",
    "    #https://www.ncbi.nlm.nih.gov/books/NBK9685/table/ch03.T.concept_names_and_sources_file_mr/\n",
    "    #https://www.ncbi.nlm.nih.gov/books/NBK9685/table/ch03.T.related_concepts_file_mrrel_rrf/\n",
    "    #https://www.nlm.nih.gov/research/umls/sourcereleasedocs/index.html    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "def processUmlsFirstTime(MRCONSOFILE,MRXW_PORFILE,MRRELFILE):\n",
    "    #import só para ter certeza\n",
    "    import os\n",
    "    import json\n",
    "    #se arquivo ja existe não rodar\n",
    "    arquivoUMLSnormalizada = 'UMLSnormalizadaMAPCLIN.txt'\n",
    "    if not os.path.exists(arquivoUMLSnormalizada):\n",
    "        UMLSfiles = (MRCONSOFILE,MRXW_PORFILE,MRRELFILE)\n",
    "        print(\"Abrindo UMLS\")\n",
    "        UMLS = u.openFiles(UMLSfiles)\n",
    "        #Wall time: 1min 3s\n",
    "        print(\"Pré-processando UMLS\")\n",
    "        UMLSNormalizada = u.selectUMLS(UMLS)\n",
    "        #Wall time: 16min 6s\n",
    "        del UMLS\n",
    "        print(\"Criando Stemm\")\n",
    "        UMLSNormalizadaSTEM = u.stemmUMLS(UMLSNormalizada)\n",
    "        #Wall time: 3min 17s\n",
    "        del UMLSNormalizada\n",
    "        print(\"Criando Lemma (DEMORA VÁRIAS HORAS!)\")\n",
    "        UMLSNormalizadaLEMMA = u.lematizaUMLS(UMLSNormalizadaSTEM)\n",
    "        #Wall time: 10h 2min 11s\n",
    "        del UMLSNormalizadaSTEM\n",
    "        # salvar as 3 variaveis\n",
    "        print(\"Salvando\")\n",
    "        with open(arquivoUMLSnormalizada, 'w') as f:\n",
    "            f.write(json.dumps(UMLSNormalizadaLEMMA))\n",
    "    \n",
    "\n",
    "#getitem é utilizado pela arvore\n",
    "_getitem0 = itemgetter(0)\n",
    "\n",
    "#https://github.com/benhoyt/pybktree\n",
    "class BKTree(object):\n",
    "    def __init__(self, distance_func, items=[]):\n",
    "        self.distance_func = distance_func\n",
    "        self.tree = None\n",
    "\n",
    "        _add = self.add\n",
    "        for item in items:\n",
    "            _add(item)\n",
    "\n",
    "    def add(self, item):\n",
    "        node = self.tree\n",
    "        if node is None:\n",
    "            self.tree = (item, {})\n",
    "            return\n",
    "\n",
    "        # Slight speed optimization -- avoid lookups inside the loop\n",
    "        _distance_func = self.distance_func\n",
    "\n",
    "        while True:\n",
    "            parent, children = node\n",
    "            distance = _distance_func(item, parent)\n",
    "            node = children.get(distance)\n",
    "            if node is None:\n",
    "                children[distance] = (item, {})\n",
    "                break\n",
    "\n",
    "    def find(self, item, n):\n",
    "        if self.tree is None:\n",
    "            return []\n",
    "\n",
    "        candidates = deque([self.tree])\n",
    "        found = []\n",
    "\n",
    "        # Slight speed optimization -- avoid lookups inside the loop\n",
    "        _candidates_popleft = candidates.popleft\n",
    "        _candidates_extend = candidates.extend\n",
    "        _found_append = found.append\n",
    "        _distance_func = self.distance_func\n",
    "\n",
    "        while candidates:\n",
    "            candidate, children = _candidates_popleft()\n",
    "            distance = _distance_func(candidate, item)\n",
    "            if distance <= n:\n",
    "                _found_append((distance, candidate))\n",
    "\n",
    "            if children:\n",
    "                lower = distance - n\n",
    "                upper = distance + n\n",
    "                _candidates_extend(c for d, c in children.items() if lower <= d <= upper)\n",
    "\n",
    "        found.sort(key=_getitem0)\n",
    "        return found\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.tree is None:\n",
    "            return\n",
    "\n",
    "        candidates = deque([self.tree])\n",
    "\n",
    "        # Slight speed optimization -- avoid lookups inside the loop\n",
    "        _candidates_popleft = candidates.popleft\n",
    "        _candidates_extend = candidates.extend\n",
    "\n",
    "        while candidates:\n",
    "            candidate, children = _candidates_popleft()\n",
    "            yield candidate\n",
    "            _candidates_extend(children.values())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{} using {} with {} top-level nodes>'.format(\n",
    "            self.__class__.__name__,\n",
    "            self.distance_func.__name__,\n",
    "            len(self.tree[1]) if self.tree is not None else 'no',\n",
    "        )\n",
    "\n",
    "# wordsList = [\"help\",\"hell\",\"helps\",\"hello\",\"shell\",\"helper\",\"loop\",\"troop\"]\n",
    "# Item = collections.namedtuple('Item', ['id','word'])\n",
    "# def levenshtein_bk(x, y): #y is the searched word, so it doesnt need to be an Item\n",
    "#     return levenshtein(x.word, y)\n",
    "# \n",
    "# wordsItems = []\n",
    "# for idp,w in enumerate(wordsList):\n",
    "#     wordsItems.append(Item(idp,w))\n",
    "# \n",
    "# tree = BKTree(levenshtein_bk, wordsItems)\n",
    "# ##tree.add(\"hand\")              # add element\n",
    "# print(sorted(tree))            # BKTree instances are iterable\n",
    "# #['hell', 'hello', 'help', 'helper', 'helps', 'loop', 'shell', 'troop']\n",
    "# sorted(tree.find(\"oop\", 2))    # find elements at most n bit away from element x\n",
    "# #[(1, 'loop'), (2, 'troop')]\n",
    "    \n",
    "        \n",
    "    \n",
    "def createBKtree(arquivoUMLSnormalizada = 'UMLSnormalizadaMAPCLIN.txt'):\n",
    "    #import só para ter certeza\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    arquivosArvores = [\"BKtreeUMLSMRCONSO1.bktree\",\n",
    "                   \"BKtreeUMLSMRCONSO2.bktree\",\n",
    "                   \"BKtreeUMLSMRCONSO3.bktree\",\n",
    "                   \"BKtreeUMLSMRXW_POR1.bktree\",\n",
    "                   \"BKtreeUMLSMRXW_POR2.bktree\",\n",
    "                   \"BKtreeUMLSMRXW_POR3.bktree\"]\n",
    "\n",
    "    #se as arvores ja foram criadas, não precisa rodar esta função\n",
    "    if os.path.exists(arquivosArvores[-1]):\n",
    "        return None\n",
    "    \n",
    "    #se arquivo input não existe\n",
    "    if not os.path.exists(arquivoUMLSnormalizada):\n",
    "        print(\"Arquivo intermediario contendo UMLS normalizada não está no diretorio ou não existe (chamar função processUmlsFirstTime)\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Abrindo arquivo contendo UMLS normalizada\")\n",
    "    with open(arquivoUMLSnormalizada, 'r') as f:\n",
    "        UMLSNormalizadaLEMMA = json.loads(f.read())\n",
    "        \n",
    "        \n",
    "    def destokeniza(texto):\n",
    "        a = \"\"\n",
    "        for token in texto:\n",
    "            a += \" \" + token.replace(\" \", \"-\")\n",
    "        return a[1:]\n",
    "    \n",
    "    Item = collections.namedtuple('Item', ['id','CUI','processadoTokenizado','processadoString','original','stemm','lemma'])\n",
    "    def levenshtein_bk_processadoString(x, y):\n",
    "        return levenshtein(x.processadoString, y.processadoString)\n",
    "    def levenshtein_bk_stemm(x, y): \n",
    "        return levenshtein(x.stemm, y.stemm)\n",
    "    def levenshtein_bk_lemma(x, y):\n",
    "        return levenshtein(destokeniza(x.lemma), destokeniza(y.lemma))  \n",
    "    \n",
    "    MRCONSO = UMLSNormalizadaLEMMA[0]\n",
    "    #MRXW_POR = UMLSNormalizadaLEMMA[1]\n",
    "    \n",
    "    #MRCONSO\n",
    "    MRCONSOitems = []\n",
    "    for data in MRCONSO:\n",
    "        MRCONSOitems.append(Item(data[0],data[1],data[2],data[3],data[4],data[5],data[6]))\n",
    "    print(\"Criando Arvore MRCONSO normal\")\n",
    "    treeMRCONSO1 = BKTree(levenshtein_bk_processadoString, MRCONSOitems)\n",
    "    fileObject = open(arquivosArvores[0], 'wb')\n",
    "    pickle.dump(treeMRCONSO1, fileObject)\n",
    "    del treeMRCONSO1\n",
    "    print(\"Criando Arvore MRCONSO stemm\")\n",
    "    treeMRCONSO2 = BKTree(levenshtein_bk_stemm, MRCONSOitems)\n",
    "    fileObject = open(arquivosArvores[1], 'wb')\n",
    "    pickle.dump(treeMRCONSO2, fileObject)\n",
    "    del treeMRCONSO2\n",
    "    print(\"Criando Arvore MRCONSO lemma\")\n",
    "    treeMRCONSO3 = BKTree(levenshtein_bk_lemma, MRCONSOitems)\n",
    "    fileObject = open(arquivosArvores[2], 'wb')\n",
    "    pickle.dump(treeMRCONSO3, fileObject)\n",
    "    del treeMRCONSO3\n",
    "    \n",
    "    \n",
    "    #MRXW_POR\n",
    "    #MRXW_PORitems = []\n",
    "    #for data in MRCONSO:\n",
    "    #    MRXW_PORitems.append(Item(data[0],data[1],data[2],data[3],data[4],data[5],data[6]))\n",
    "    #print(\"Criando Arvore MRXW_POR normal\")\n",
    "    #treeMRXW_POR1 = BKTree(levenshtein_bk_processadoString, MRXW_PORitems)\n",
    "    #fileObject = open(arquivosArvores[3], 'wb')\n",
    "    #pickle.dump(treeMRXW_POR1, fileObject)\n",
    "    #del treeMRXW_POR1\n",
    "    #print(\"Criando Arvore MRXW_POR stemm\")\n",
    "    #treeMRXW_POR2 = BKTree(levenshtein_bk_stemm, MRXW_PORitems)\n",
    "    #fileObject = open(arquivosArvores[4], 'wb')\n",
    "    #pickle.dump(treeMRXW_POR2, fileObject)\n",
    "    #del treeMRXW_POR2\n",
    "    #print(\"Criando Arvore MRXW_POR lemma\")\n",
    "    #treeMRXW_POR3 = BKTree(levenshtein_bk_lemma, MRXW_PORitems)\n",
    "    #fileObject = open(arquivosArvores[5], 'wb')\n",
    "    #pickle.dump(treeMRXW_POR3, fileObject)\n",
    "    #del treeMRXW_POR3\n",
    "    #Wall time: 51min 11s\n",
    "       \n",
    "def createSCTfiles(MRCONSOFILE,MRRELFILE):\n",
    "    #import só para ter certeza\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    UMLStoSNOMEDfiles = [\"snomed.txt\",\n",
    "                         \"SY.txt\",\n",
    "                         \"REL_SNOMED.txt\"]\n",
    "    #se os arquivos ja foram criados, não precisa rodar esta função\n",
    "    if os.path.exists(UMLStoSNOMEDfiles[-1]):\n",
    "        return None\n",
    "    \n",
    "    snomed,SY,REL_SNOMED = u.openFilesUMLStoSNOMED(MRCONSOFILE,MRRELFILE)\n",
    "    #Wall time: 1min 57s\n",
    "    \n",
    "    with open(UMLStoSNOMEDfiles[0], 'w') as f:\n",
    "        f.write(json.dumps(snomed))\n",
    "    with open(UMLStoSNOMEDfiles[1], 'w') as f:\n",
    "        f.write(json.dumps(SY))\n",
    "    with open(UMLStoSNOMEDfiles[2], 'w') as f:\n",
    "        f.write(json.dumps(REL_SNOMED))\n",
    "\n",
    "        \n",
    "#funcoes soltas (necessarias)\n",
    "def destokeniza(texto):\n",
    "    a = \"\"\n",
    "    for token in texto:\n",
    "        a += \" \" + token.replace(\" \", \"-\")\n",
    "    return a[1:]\n",
    "Item = collections.namedtuple('Item', ['id','CUI','processadoTokenizado','processadoString','original','stemm','lemma'])\n",
    "def levenshtein_bk_processadoString(x, y):\n",
    "    return levenshtein(x.processadoString, y.processadoString)\n",
    "def levenshtein_bk_stemm(x, y): \n",
    "    return levenshtein(x.stemm, y.stemm)\n",
    "def levenshtein_bk_lemma(x, y):\n",
    "    return levenshtein(destokeniza(x.lemma), destokeniza(y.lemma))  \n",
    "\n",
    "\n",
    "#Singleton    \n",
    "class OpenBKtreeClass:\n",
    "    __instance = None\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def getInstance(cls):\n",
    "        if not cls.__instance:\n",
    "            cls.__instance = OpenBKtreeClass()\n",
    "            cls.__instance.openBKtree()\n",
    "        return cls.__instance\n",
    "    \n",
    "    def openBKtree(self):\n",
    "        print(\"Abrindo arvore UMLS\")\n",
    "        # abrir BK-tree\n",
    "        arquivosArvores = [\"BKtreeUMLSMRCONSO1.bktree\",\n",
    "                       \"BKtreeUMLSMRCONSO2.bktree\",\n",
    "                       \"BKtreeUMLSMRCONSO3.bktree\",\n",
    "                       \"BKtreeUMLSMRXW_POR1.bktree\",\n",
    "                       \"BKtreeUMLSMRXW_POR2.bktree\",\n",
    "                       \"BKtreeUMLSMRXW_POR3.bktree\"]\n",
    "        \n",
    "        treesUMLS = []\n",
    "        fileObject = open(arquivosArvores[0], 'rb')\n",
    "        treesUMLS.append(pickle.load(fileObject))\n",
    "        fileObject = open(arquivosArvores[1], 'rb')\n",
    "        treesUMLS.append(pickle.load(fileObject))\n",
    "        fileObject = open(arquivosArvores[2], 'rb')\n",
    "        treesUMLS.append(pickle.load(fileObject))\n",
    "        #fileObject = open(arquivosArvores[3], 'rb')\n",
    "        #treesUMLS.append(pickle.load(fileObject))\n",
    "        #fileObject = open(arquivosArvores[4], 'rb')\n",
    "        #treesUMLS.append(pickle.load(fileObject))\n",
    "        #fileObject = open(arquivosArvores[5], 'rb')\n",
    "        #treesUMLS.append(pickle.load(fileObject))\n",
    "        #Wall time: 43.7 s\n",
    "        self.treesUMLS = treesUMLS\n",
    "    \n",
    "#Singleton    \n",
    "class OpenSCTfilesClass:\n",
    "    __instance = None\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def getInstance(cls):\n",
    "        if not cls.__instance:\n",
    "            cls.__instance = OpenSCTfilesClass()\n",
    "            cls.__instance.openSCTfiles()\n",
    "        return cls.__instance\n",
    "       \n",
    "    def openSCTfiles(self):\n",
    "        print(\"Abrindo arquivos SCT\")\n",
    "        UMLStoSNOMEDfiles = [\"snomed.txt\",\n",
    "                             \"SY.txt\",\n",
    "                             \"REL_SNOMED.txt\"]\n",
    "        \n",
    "        UMLStoSNOMEDdata = []\n",
    "        with open(UMLStoSNOMEDfiles[0], 'r') as f:\n",
    "            UMLStoSNOMEDdata.append(json.loads(f.read()))\n",
    "        with open(UMLStoSNOMEDfiles[1], 'r') as f:\n",
    "            UMLStoSNOMEDdata.append(json.loads(f.read()))\n",
    "        with open(UMLStoSNOMEDfiles[2], 'r') as f:\n",
    "            UMLStoSNOMEDdata.append(json.loads(f.read()))\n",
    "        #Wall time: 29.2 s\n",
    "        self.UMLStoSNOMEDdata = UMLStoSNOMEDdata\n",
    "            \n",
    "    \n",
    "class EstadoCodigoSCT:\n",
    "    def __init__(self):\n",
    "        self.ativoEspecificado = \"A-Conceito Ativo e Totalmente Especificado\"\n",
    "        self.ativo = \"B-Conceito Ativo\"\n",
    "        self.obsoleto = \"C-Conceito Obsoleto\"\n",
    "        \n",
    "class DataStructureOutputSearchTerm:\n",
    "    def __init__(self):\n",
    "        self.searchTerm = None\n",
    "        self.UMLSmatches = []\n",
    "\n",
    "    def toString(self):\n",
    "        if self.searchTerm == None:\n",
    "            return \"\"        \n",
    "        st = \"\"\n",
    "        st += \"Termo Buscado: \"+self.searchTerm+\"\\n\"\n",
    "        for UMLSmatch in self.UMLSmatches:\n",
    "            st += \"Possui relação com codigo UMLS:\\n\" + UMLSmatch.toString()   \n",
    "        return st     \n",
    "        \n",
    "    def toPandas(self):\n",
    "        df = pd.DataFrame(columns=['Termo Buscado',\n",
    "                           'CUI',\n",
    "                           'Termo UMLS',\n",
    "                           'Regra UMLS',\n",
    "                           'Distancia Levenshtein',\n",
    "                           'Codigo SCT',\n",
    "                           'Termo SCT',\n",
    "                           'Estado SCT',\n",
    "                           'Preferencia SCT'])\n",
    "\n",
    "        if len(self.UMLSmatches) == 0:\n",
    "            df = df.append({'Termo Buscado': self.searchTerm,\n",
    "                       'CUI':\"\",\n",
    "                       'Termo UMLS':\"\",\n",
    "                       'Regra UMLS':\"\",\n",
    "                       'Distancia Levenshtein':\"\",\n",
    "                       'Codigo SCT':\"\",\n",
    "                       'Termo SCT':\"\",\n",
    "                       'Estado SCT':\"\",\n",
    "                       'Preferencia SCT':\"\"}, ignore_index=True)\n",
    "            \n",
    "        for UMLSmatch in self.UMLSmatches:\n",
    "            if len(UMLSmatch.SCTmatches) == 0:\n",
    "                df = df.append({'Termo Buscado': self.searchTerm,\n",
    "                           'CUI':UMLSmatch.CUI,\n",
    "                           'Termo UMLS':UMLSmatch.original,\n",
    "                           'Regra UMLS':UMLSmatch.regraUMLS,\n",
    "                           'Distancia Levenshtein':UMLSmatch.distance,\n",
    "                           'Codigo SCT':\"\",\n",
    "                           'Termo SCT':\"\",\n",
    "                           'Estado SCT':\"\",\n",
    "                           'Preferencia SCT':\"\"}, ignore_index=True)\n",
    "                \n",
    "            for SCTmatch in UMLSmatch.SCTmatches:\n",
    "                df = df.append({'Termo Buscado': self.searchTerm,\n",
    "                           'CUI':UMLSmatch.CUI,\n",
    "                           'Termo UMLS':UMLSmatch.original,\n",
    "                           'Regra UMLS':UMLSmatch.regraUMLS,\n",
    "                           'Distancia Levenshtein':UMLSmatch.distance,\n",
    "                           'Codigo SCT':SCTmatch.CODESCT,\n",
    "                           'Termo SCT':SCTmatch.STR,\n",
    "                           'Estado SCT':SCTmatch.status,\n",
    "                           'Preferencia SCT':SCTmatch.ISPREF}, ignore_index=True)\n",
    "                \n",
    "        df = df.sort_values(by='Preferencia SCT', ascending=True)\n",
    "        df = df.sort_values(by='Estado SCT', ascending=True)\n",
    "        df = df.drop_duplicates() \n",
    "        return df\n",
    "        \n",
    "class DataStructureOutputUMLSmatch:\n",
    "    def __init__(self):\n",
    "        self.regraUMLS = None\n",
    "        self.distance = None\n",
    "        self.id = None\n",
    "        self.CUI = None\n",
    "        self.processadoTokenizado = None\n",
    "        self.processadoString = None\n",
    "        self.original = None\n",
    "        self.stemm = None\n",
    "        self.lemma = None\n",
    "        self.SCTmatches = []\n",
    "        \n",
    "    def toString(self):\n",
    "        if self.CUI == None:\n",
    "            return \"\"\n",
    "        st = \"\"\n",
    "        st += \"\\tCUI: \"+self.CUI+\"\\n\"\n",
    "        st += \"\\tTermo UMLS: \"+self.original+\"\\n\"\n",
    "        st += \"\\tObtido com: \"+self.regraUMLS+\"\\n\"\n",
    "        st += \"\\tDistancia: \"+str(self.distance)+\"\\n\"\n",
    "        for SCTmatch in self.SCTmatches:\n",
    "            st += \"\\tPossui relação com codigo SCT:\\n\" + SCTmatch.toString()\n",
    "        return st\n",
    "    \n",
    "class DataStructureOutputSCTmatch:\n",
    "    def __init__(self):\n",
    "        self.y = None     \n",
    "        self.regraSCT = None \n",
    "        self.CODESCT = None     \n",
    "        self.STR = None     \n",
    "        self.TTY = None      \n",
    "        self.status = None     \n",
    "        self.ISPREF = None     \n",
    "        self.STT = None #talvez deletar      \n",
    "        self.matchedCUI = None     \n",
    "        self.RELA = None     \n",
    "        \n",
    "    def toString(self):\n",
    "        if self.CODESCT == None:\n",
    "            return \"\"\n",
    "        st = \"\"\n",
    "        st += \"\\t\\tCodigo: \"+self.CODESCT+\"\\n\"\n",
    "        st += \"\\t\\tTermo SCT: \"+self.STR+\"\\n\"\n",
    "        st += \"\\t\\tStatus: \"+self.status+\" pois possui TTY:\"+self.TTY+\"\\n\"\n",
    "        st += \"\\t\\tPreferência: \"+self.ISPREF+\"\\n\"\n",
    "        st += \"\\t\\tMatch com CUI: \"+self.matchedCUI+\"\\n\"\n",
    "        if self.RELA != None:\n",
    "            st += \"\\t\\tRelação: \"+self.RELA+\"\\n\"\n",
    "        if self.regraSCT != None:\n",
    "            st += \"\\t\\tObtido com: \"+self.regraSCT+\"\\n\"\n",
    "        return st\n",
    "        \n",
    "\n",
    "class TemposExecucao:\n",
    "    def __init__(self):\n",
    "        self.R1 = None\n",
    "        self.R2 = None\n",
    "        self.R3 = None\n",
    "        self.R4 = None\n",
    "        self.R5 = None\n",
    "        self.R6 = None\n",
    "        self.R7 = None\n",
    "        self.BUSCA = None\n",
    "        self.C12 = None\n",
    "        self.C3 = None\n",
    "        self.C4 = None\n",
    "    \n",
    "    def criaEstatistica(self,listaTempos):\n",
    "        tempo = datetime.datetime.now()\n",
    "        tempo = tempo - tempo\n",
    "        soma = TemposExecucao()       \n",
    "        soma.R1 = tempo\n",
    "        soma.R2 = tempo\n",
    "        soma.R3 = tempo\n",
    "        soma.R4 = tempo\n",
    "        soma.R5 = tempo\n",
    "        soma.R6 = tempo\n",
    "        soma.R7 = tempo\n",
    "        soma.BUSCA = tempo\n",
    "        soma.C12 = tempo\n",
    "        soma.C3 = tempo\n",
    "        soma.C4 = tempo \n",
    "        quantidadeUso = TemposExecucao()\n",
    "        quantidadeUso.R1 = 0\n",
    "        quantidadeUso.R2 = 0\n",
    "        quantidadeUso.R3 = 0\n",
    "        quantidadeUso.R4 = 0\n",
    "        quantidadeUso.R5 = 0\n",
    "        quantidadeUso.R6 = 0\n",
    "        quantidadeUso.R7 = 0\n",
    "        quantidadeUso.BUSCA = 0\n",
    "        quantidadeUso.C12 = 0\n",
    "        quantidadeUso.C3 = 0\n",
    "        quantidadeUso.C4 = 0\n",
    "        for tempos in listaTempos:\n",
    "            if tempos.R1 != None:\n",
    "                soma.R1 += tempos.R1\n",
    "                quantidadeUso.R1 += 1\n",
    "            if tempos.R2 != None:\n",
    "                soma.R2 += tempos.R2\n",
    "                quantidadeUso.R2 += 1\n",
    "            if tempos.R3 != None:\n",
    "                soma.R3 += tempos.R3\n",
    "                quantidadeUso.R3 += 1\n",
    "            if tempos.R4 != None:\n",
    "                soma.R4 += tempos.R4\n",
    "                quantidadeUso.R4 += 1\n",
    "            if tempos.R5 != None:\n",
    "                soma.R5 += tempos.R5\n",
    "                quantidadeUso.R5 += 1\n",
    "            if tempos.R6 != None:\n",
    "                soma.R6 += tempos.R6\n",
    "                quantidadeUso.R6 += 1\n",
    "            if tempos.R7 != None:\n",
    "                soma.R7 += tempos.R7\n",
    "                quantidadeUso.R7 += 1\n",
    "            if tempos.BUSCA != None:\n",
    "                soma.BUSCA += tempos.BUSCA\n",
    "                quantidadeUso.BUSCA += 1\n",
    "            if tempos.C12 != None:\n",
    "                soma.C12 += tempos.C12\n",
    "                quantidadeUso.C12 += 1\n",
    "            if tempos.C3 != None:\n",
    "                soma.C3 += tempos.C3\n",
    "                quantidadeUso.C3 += 1\n",
    "            if tempos.C4 != None:\n",
    "                soma.C4 += tempos.C4\n",
    "                quantidadeUso.C4 += 1\n",
    "      \n",
    "        media = TemposExecucao()  \n",
    "        media.R1 =    ( soma.R1.microseconds/   quantidadeUso.R1    ) \n",
    "        media.R2 =    ( soma.R2.microseconds/   quantidadeUso.R2    ) \n",
    "        media.R3 =    ( soma.R3.microseconds/   quantidadeUso.R3    ) \n",
    "        media.R4 =    ( soma.R4.microseconds/   quantidadeUso.R4    ) \n",
    "        media.R5 =    ( soma.R5.microseconds/   quantidadeUso.R5    ) \n",
    "        media.R6 =    ( soma.R6.microseconds/   quantidadeUso.R6    ) \n",
    "        media.R7 = 0# (    soma.R7.microseconds/   quantidadeUso.R7 ) \n",
    "        media.BUSCA = ( soma.BUSCA.microseconds/quantidadeUso.BUSCA ) \n",
    "        media.C12 =   ( soma.C12.microseconds/  quantidadeUso.C12   ) \n",
    "        media.C3 =    ( soma.C3.microseconds/   quantidadeUso.C3    ) \n",
    "        media.C4 =    ( soma.C4.microseconds/   quantidadeUso.C4    ) \n",
    "        \n",
    "        return quantidadeUso,media    \n",
    "        \n",
    "        \n",
    "class Map:\n",
    "    def __init__(self,preProcessamentoclass):\n",
    "        self.preProcessamento = preProcessamentoclass\n",
    "    \n",
    "    def regraSinonim(self,texto,arvoresUMLS,distanciaMaxima): #DEVE RETORNAR A DIFERENÇA NA QUANTIDADE DE TOKENS (outra funcao faz isso)\n",
    "        if distanciaMaxima != 0:\n",
    "            distanciaMaxima -= 1\n",
    "        \n",
    "        arvoreUMLS1 = arvoresUMLS[0]\n",
    "        arvoreUMLS2 = arvoresUMLS[1]\n",
    "        arvoreUMLS3 = arvoresUMLS[2]\n",
    "        \n",
    "        dicio = Dicio()\n",
    "        conceitosCandidatosNAOIDENTICOS = []\n",
    "        if len(texto) == 0:\n",
    "            return []\n",
    "        elif len(texto) == 1: #possui um unico token\n",
    "            tokenEncontrado = dicio.search(texto[0])\n",
    "            if tokenEncontrado == None:\n",
    "                return []\n",
    "            sinonimos = tokenEncontrado.synonyms\n",
    "            for sinonimo in sinonimos:\n",
    "                sinonimo = sinonimo.word\n",
    "                sinonimo = self.preProcessamento.processaMAPCLIN(sinonimo)\n",
    "                _,conceitosEncontradosD = self.regraDiretaTree(sinonimo,arvoreUMLS1,distanciaMaxima)\n",
    "                conceitosEncontradosL = self.regraLemmaTree(self.preProcessamento.lematizador(sinonimo),arvoreUMLS3,distanciaMaxima)\n",
    "                conceitosEncontradosS = self.regraStemmTree(self.preProcessamento.stemmer(self.preProcessamento.destokeniza(sinonimo)),arvoreUMLS2,distanciaMaxima)\n",
    "                if len(conceitosEncontradosD) > 0:\n",
    "                    conceitosCandidatosNAOIDENTICOS.extend(conceitosEncontradosD)\n",
    "                if len(conceitosEncontradosL) > 0:\n",
    "                    conceitosCandidatosNAOIDENTICOS.extend(conceitosEncontradosL)\n",
    "                if len(conceitosEncontradosS) > 0:\n",
    "                    conceitosCandidatosNAOIDENTICOS.extend(conceitosEncontradosS)\n",
    "            return conceitosCandidatosNAOIDENTICOS\n",
    "        else:\n",
    "            conceitosCtoken = []\n",
    "            for token in texto:\n",
    "                tokenEncontrado = dicio.search(texto[0])\n",
    "                if tokenEncontrado == None:\n",
    "                    continue\n",
    "                sinonimos = tokenEncontrado.synonyms\n",
    "                for sinonimo in sinonimos:\n",
    "                    sinonimo = sinonimo.word\n",
    "                    sinonimo = self.preProcessamento.processaMAPCLIN(sinonimo)\n",
    "                    _,conceitosEncontradosD = self.regraDiretaTree(sinonimo,arvoreUMLS1,distanciaMaxima)\n",
    "                    conceitosEncontradosL = self.regraLemmaTree(self.preProcessamento.lematizador(sinonimo),arvoreUMLS3,distanciaMaxima)\n",
    "                    conceitosEncontradosS = self.regraStemmTree(self.preProcessamento.stemmer(self.preProcessamento.destokeniza(sinonimo)),arvoreUMLS2,distanciaMaxima)\n",
    "                    if len(conceitosEncontradosD) > 0:\n",
    "                        conceitosCtoken.extend(tuple(conceitosEncontradosD))\n",
    "                    if len(conceitosEncontradosL) > 0:\n",
    "                        conceitosCtoken.extend(tuple(conceitosEncontradosL))\n",
    "                    if len(conceitosEncontradosS) > 0:\n",
    "                        conceitosCtoken.extend(tuple(conceitosEncontradosS))\n",
    "                        \n",
    "            for conceito in purge_dublicates(conceitosCtoken): \n",
    "                #se possui 1 palavra a mais ou a menos, ou igual\n",
    "                if abs(len(conceito[1].processadoTokenizado) - len(texto)) <= 1:\n",
    "                    conceitosCandidatosNAOIDENTICOS.append(conceito)\n",
    "            return conceitosCandidatosNAOIDENTICOS         \n",
    "                                    \n",
    "        \n",
    "    def regraPai(self,texto,arvoresUMLS,distanciaMaxima):        \n",
    "        arvoreUMLS1 = arvoresUMLS[0]\n",
    "        arvoreUMLS2 = arvoresUMLS[1]\n",
    "        arvoreUMLS3 = arvoresUMLS[2]\n",
    "        if len(texto) > 1:\n",
    "            conceitosCandidatosNAOIDENTICOS = []\n",
    "            conceitosCtoken = []\n",
    "            for token in texto:\n",
    "                token = [token]\n",
    "                _,conceitosEncontradosD = self.regraDiretaTree(token,arvoreUMLS1,distanciaMaxima)\n",
    "                conceitosEncontradosL = self.regraLemmaTree(token,arvoreUMLS3,distanciaMaxima)\n",
    "                conceitosEncontradosS = self.regraStemmTree(token,arvoreUMLS2,distanciaMaxima)\n",
    "                if len(conceitosEncontradosD) > 0:\n",
    "                    conceitosCtoken.extend(tuple(conceitosEncontradosD))\n",
    "                if len(conceitosEncontradosL) > 0:\n",
    "                    conceitosCtoken.extend(tuple(conceitosEncontradosL))\n",
    "                if len(conceitosEncontradosS) > 0:\n",
    "                    conceitosCtoken.extend(tuple(conceitosEncontradosS))\n",
    "                    \n",
    "            for conceito in purge_dublicates(conceitosCtoken): \n",
    "            #for conceito in set(conceitosCtoken):\n",
    "                #originalMapclin -> if (conceitosCtoken.count(conceito) >= 2 or len(conceito) == 1) and conceito not in conceitosCandidatosNAOIDENTICOS:\n",
    "                #conceitotokenized = self.preProcessamento.tokeniza(conceito[0])\n",
    "                conceitotokenized = conceito[1].processadoTokenizado\n",
    "                #if conceitosCtoken.count(conceito[0]) >= len(conceitotokenized) and conceito[0] not in conceitosCandidatosNAOIDENTICOS:\n",
    "                if (conceitosCtoken.count(conceito) >= 2 or len(conceitotokenized) == 1) and conceito not in conceitosCandidatosNAOIDENTICOS:\n",
    "                    conceitosCandidatosNAOIDENTICOS.append(conceito)          \n",
    "            return conceitosCandidatosNAOIDENTICOS         \n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "        \n",
    "    def regraFilho(self,texto,arvoresUMLS,distanciaMaxima):       \n",
    "        arvoreUMLS1 = arvoresUMLS[0]\n",
    "        arvoreUMLS2 = arvoresUMLS[1]\n",
    "        arvoreUMLS3 = arvoresUMLS[2]\n",
    "        \n",
    "        conceitosCandidatosNAOIDENTICOS = []\n",
    "        conceitosCtoken = []\n",
    "        for token in texto:\n",
    "            token = [token]\n",
    "            _,conceitosEncontradosD = self.regraDiretaTree(token,arvoreUMLS1,distanciaMaxima)\n",
    "            conceitosEncontradosL = self.regraLemmaTree(token,arvoreUMLS3,distanciaMaxima)\n",
    "            conceitosEncontradosS = self.regraStemmTree(token,arvoreUMLS2,distanciaMaxima)\n",
    "            if len(conceitosEncontradosD) > 0:\n",
    "                conceitosCtoken.extend(tuple(conceitosEncontradosD))\n",
    "            if len(conceitosEncontradosL) > 0:\n",
    "                conceitosCtoken.extend(tuple(conceitosEncontradosL))\n",
    "            if len(conceitosEncontradosS) > 0:\n",
    "                conceitosCtoken.extend(tuple(conceitosEncontradosS))\n",
    "                \n",
    "        \n",
    "        for conceito in purge_dublicates(conceitosCtoken): \n",
    "        #for conceito in set(conceitosCtoken):\n",
    "            #if (conceitosCtoken.count(conceito) >= 2 or len(conceito) == 1) and conceito not in conceitosCandidatosNAOIDENTICOS:\n",
    "            #conceitotokenized = self.preProcessamento.tokeniza(conceito[0])\n",
    "            conceitotokenized = conceito[1].processadoTokenizado\n",
    "            #if len(conceitotokenized) >= len(texto) and conceito[0] not in conceitosCandidatosNAOIDENTICOS:\n",
    "            \n",
    "            if len(conceitotokenized) >= len(texto) and conceito not in conceitosCandidatosNAOIDENTICOS:\n",
    "                conceitosCandidatosNAOIDENTICOS.append(conceito)\n",
    "        \n",
    "        return conceitosCandidatosNAOIDENTICOS    \n",
    "        \n",
    "        \n",
    "    def regraIngles(self,texto,dadosUMLS):\n",
    "        #usou metamap\n",
    "        #testar outras ferramentas, como ctakes, etc...\n",
    "        return []\n",
    "        \n",
    "        \n",
    "    def regraDiretaTree(self,texto,arvoreUMLS,distanciaMaxima):\n",
    "        \n",
    "        textoD = self.preProcessamento.destokeniza(texto)\n",
    "        Item = collections.namedtuple('Item', ['processadoString'])  \n",
    "        itemTextoD = Item(textoD)\n",
    "            \n",
    "        termosSimilares = sorted(arvoreUMLS.find(itemTextoD, distanciaMaxima))\n",
    "        \n",
    "        #se existe palavra com distancia 0\n",
    "        conceitosCandidatosIdenticos = []\n",
    "        for termosimilar in termosSimilares:\n",
    "            if termosimilar[0] == 0:\n",
    "                conceitosCandidatosIdenticos.append(termosimilar)\n",
    "                \n",
    "        if len(conceitosCandidatosIdenticos) == 0:\n",
    "            return False, termosSimilares\n",
    "        else:\n",
    "            return True, conceitosCandidatosIdenticos\n",
    "        \n",
    "    def regraLemmaTree(self,texto,arvoreUMLS,distanciaMaxima):\n",
    "        textoD = self.preProcessamento.destokeniza(texto)\n",
    "        Item = collections.namedtuple('Item', ['lemma'])  \n",
    "        itemTextoD = Item(textoD)\n",
    "            \n",
    "        termosSimilares = sorted(arvoreUMLS.find(itemTextoD, distanciaMaxima))\n",
    "        \n",
    "        return termosSimilares     \n",
    "        \n",
    "    def regraStemmTree(self,texto,arvoreUMLS,distanciaMaxima):\n",
    "        textoD = self.preProcessamento.destokeniza(texto)\n",
    "        Item = collections.namedtuple('Item', ['stemm'])  \n",
    "        itemTextoD = Item(textoD)\n",
    "            \n",
    "        termosSimilares = sorted(arvoreUMLS.find(itemTextoD, distanciaMaxima))\n",
    "        \n",
    "        return termosSimilares    \n",
    "    \n",
    "    \n",
    "    def createOutputUMLS(self,output,conceitoCandidato,regra):\n",
    "        outputUMLSmatch = DataStructureOutputUMLSmatch()\n",
    "        outputUMLSmatch.regraUMLS = regra\n",
    "        outputUMLSmatch.distance = conceitoCandidato[0]\n",
    "        outputUMLSmatch.id = conceitoCandidato[1].id\n",
    "        outputUMLSmatch.CUI = conceitoCandidato[1].CUI\n",
    "        outputUMLSmatch.processadoTokenizado = conceitoCandidato[1].processadoTokenizado\n",
    "        outputUMLSmatch.processadoString = conceitoCandidato[1].processadoString\n",
    "        outputUMLSmatch.original = conceitoCandidato[1].original\n",
    "        outputUMLSmatch.stemm = conceitoCandidato[1].stemm\n",
    "        outputUMLSmatch.lemma = conceitoCandidato[1].lemma\n",
    "        \n",
    "        output.UMLSmatches.append(outputUMLSmatch)\n",
    "        return output\n",
    "    \n",
    "    def mapToUMLStree(self,texto,arvoresUMLS,distanciaMaxima,output,temposExecucao,rules=[1,1,1,1,1,1]):\n",
    "\n",
    "        arvoreUMLS1 = arvoresUMLS[0]\n",
    "        arvoreUMLS2 = arvoresUMLS[1]\n",
    "        arvoreUMLS3 = arvoresUMLS[2]\n",
    "        #arvoreUMLS4 = arvoresUMLS[3]\n",
    "        #arvoreUMLS5 = arvoresUMLS[4]\n",
    "        #arvoreUMLS6 = arvoresUMLS[5]\n",
    "        \n",
    "        if rules[0] == 1:\n",
    "            a = datetime.datetime.now()\n",
    "            isEqualMatch, conceitosCandidatos = self.regraDiretaTree(texto,arvoreUMLS1,distanciaMaxima)\n",
    "            if isEqualMatch: # se regra direta tiver distancia 0, deu match\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA DIRETA\")\n",
    "                b = datetime.datetime.now()\n",
    "                temposExecucao.R1 = b-a\n",
    "                return temposExecucao, output\n",
    "            \n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA DIRETA\")\n",
    "                \n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R1 = b-a\n",
    "        \n",
    "    \n",
    "        if rules[1] == 1:\n",
    "            a = datetime.datetime.now()        \n",
    "            conceitosCandidatos = self.regraLemmaTree(texto,arvoreUMLS3,distanciaMaxima)\n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA LEMMA\")\n",
    "                \n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R2 = b-a\n",
    "        \n",
    "        \n",
    "        if rules[2] == 1:\n",
    "            a = datetime.datetime.now()\n",
    "            conceitosCandidatos = self.regraStemmTree(texto,arvoreUMLS2,distanciaMaxima)\n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA STEMM\")\n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R3 = b-a\n",
    "        \n",
    "        \n",
    "        if rules[3] == 1:\n",
    "            a = datetime.datetime.now()        \n",
    "            conceitosCandidatos = self.regraSinonim(texto,arvoresUMLS,distanciaMaxima)\n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA SINONIMO\")\n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R4 = b-a\n",
    "\n",
    "        if rules[4] == 1:\n",
    "            a = datetime.datetime.now()            \n",
    "            conceitosCandidatos = self.regraPai(texto,arvoresUMLS,distanciaMaxima)\n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA PAI\")\n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R5 = b-a\n",
    "            \n",
    "            \n",
    "        if rules[5] == 1:\n",
    "            a = datetime.datetime.now()\n",
    "            conceitosCandidatos = self.regraFilho(texto,arvoresUMLS,distanciaMaxima)\n",
    "            if len(conceitosCandidatos) > 0:\n",
    "                for conceitoCandidato in conceitosCandidatos:\n",
    "                    output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA FILHO\")\n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.R6 = b-a\n",
    "        \n",
    "        #if rules[7] == 1:\n",
    "        #    a = datetime.datetime.now()        \n",
    "        #    conceitosCandidatos = self.regraIngles(texto,dadosUMLS)\n",
    "        #    if len(conceitosCandidatos) > 0:\n",
    "        #        for conceitoCandidato in conceitosCandidatos:\n",
    "        #            output = self.createOutputUMLS(output,conceitoCandidato,\"REGRA FILHO\")\n",
    "        #    b = datetime.datetime.now()\n",
    "        #    temposExecucao.R7 = b-a\n",
    "\n",
    "        \n",
    "        return temposExecucao,output\n",
    "    \n",
    "     \n",
    "    \n",
    "    def buscaSCT(self,output,snomed):\n",
    "        codigosSCT = []\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for snomedTerm in snomed:\n",
    "                if snomedTerm[3] == UMLSmatch.CUI and snomedTerm not in codigosSCT:\n",
    "                    \n",
    "                    outputSCTmatch = DataStructureOutputSCTmatch()\n",
    "                    outputSCTmatch.y = snomedTerm[0]  \n",
    "                    outputSCTmatch.CODESCT = snomedTerm[1]     \n",
    "                    outputSCTmatch.STR = snomedTerm[2]            \n",
    "                    outputSCTmatch.matchedCUI = snomedTerm[3]   \n",
    "                    outputSCTmatch.TTY = snomedTerm[4] \n",
    "                    outputSCTmatch.ISPREF = snomedTerm[5]    \n",
    "                    outputSCTmatch.STT = snomedTerm[6] #talvez deletar \n",
    "                    \n",
    "                    UMLSmatch.SCTmatches.append(outputSCTmatch)\n",
    "                    \n",
    "                    codigosSCT.append(snomedTerm)\n",
    "                    \n",
    "        if len(codigosSCT) > 0:\n",
    "            return True, output\n",
    "        return False, output\n",
    "    \n",
    "    \n",
    "    def classificaStatus(self,output):\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for outputSCTmatch in UMLSmatch.SCTmatches:\n",
    "                TTY = outputSCTmatch.TTY\n",
    "                if TTY == \"FN\":\n",
    "                    outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":\n",
    "                    outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                else:\n",
    "                    outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "        return output\n",
    "    \n",
    "    def caso12(self,output):\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for outputSCTmatch in UMLSmatch.SCTmatches:\n",
    "                outputSCTmatch.regraSCT = \"CASO12\"\n",
    "        return output\n",
    "    \n",
    "    def caso3(self,output,snomed,SY,REL_SNOMED):\n",
    "        codigosSCT = []\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for outputSCTmatch in UMLSmatch.SCTmatches:\n",
    "                CUIumls = UMLSmatch.CUI\n",
    "                for rSY in SY:\n",
    "                    if rSY[1] == CUIumls:\n",
    "                        \n",
    "                        for snomedTerm in snomed:\n",
    "                            if snomedTerm[3] == rSY[2] and snomedTerm not in codigosSCT:\n",
    "                                TTY = snomedTerm[4]\n",
    "                                if TTY == \"FN\":         \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[2]\n",
    "                                    outputSCTmatch.RELA = \"SY\"       \n",
    "                                elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[2]\n",
    "                                    outputSCTmatch.RELA = \"SY\"   \n",
    "                                else:      \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[2]\n",
    "                                    outputSCTmatch.RELA = \"SY\"         \n",
    "                                codigosSCT.append(snomedTerm)\n",
    "                    elif rSY[2] == CUIumls:\n",
    "            \n",
    "                        for snomedTerm in snomed:\n",
    "                            if snomedTerm[3] == rSY[1] and snomedTerm not in codigosSCT:\n",
    "                                TTY = snomedTerm[4]\n",
    "                                if TTY == \"FN\":        \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[1]\n",
    "                                    outputSCTmatch.RELA = \"SY\"   \n",
    "                                elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[1]\n",
    "                                    outputSCTmatch.RELA = \"SY\"   \n",
    "                                else:      \n",
    "                                    outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                                    outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+rSY[1]\n",
    "                                    outputSCTmatch.RELA = \"SY\"           \n",
    "                                codigosSCT.append(snomedTerm)\n",
    "                for relsno in REL_SNOMED:\n",
    "                    rela = relsno[5]\n",
    "                    if rela == \"possibly_equivalent_to\" or rela == \"same_as\":\n",
    "                        if relsno[1] == CUIumls:\n",
    "                        \n",
    "                            for snomedTerm in snomed:\n",
    "                                if snomedTerm[3] == relsno[2] and snomedTerm not in codigosSCT:\n",
    "                                    TTY = snomedTerm[4]\n",
    "                                    if TTY == \"FN\":    \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[2]\n",
    "                                        outputSCTmatch.RELA = rela       \n",
    "                                    elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[2]\n",
    "                                        outputSCTmatch.RELA = rela    \n",
    "                                    else:      \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[2]\n",
    "                                        outputSCTmatch.RELA = rela          \n",
    "                                    codigosSCT.append(snomedTerm)\n",
    "                        elif relsno[2] == CUIumls:\n",
    "                \n",
    "                            for snomedTerm in snomed:\n",
    "                                if snomedTerm[3] == relsno[1] and snomedTerm not in codigosSCT:\n",
    "                                    TTY = snomedTerm[4]\n",
    "                                    if TTY == \"FN\":   \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[1]\n",
    "                                        outputSCTmatch.RELA = rela       \n",
    "                                    elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[1]\n",
    "                                        outputSCTmatch.RELA = rela    \n",
    "                                    else:      \n",
    "                                        outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                                        outputSCTmatch.matchedCUI = outputSCTmatch.matchedCUI+\"+\"+relsno[1]\n",
    "                                        outputSCTmatch.RELA = rela              \n",
    "                                    codigosSCT.append(snomedTerm)\n",
    "                        \n",
    "        \n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for outputSCTmatch in UMLSmatch.SCTmatches:\n",
    "                outputSCTmatch.regraSCT = \"CASO3\"                \n",
    "                        \n",
    "        return output\n",
    "    \n",
    "    def caso4(self,output,snomed,SY):     \n",
    "        codigosSCT = []\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            CUIumls = UMLSmatch.CUI                \n",
    "            for rSY in SY:\n",
    "                if rSY[1] == CUIumls:\n",
    "                    for snomedTerm in snomed:\n",
    "                        if snomedTerm[3] == rSY[2] and snomedTerm not in codigosSCT:\n",
    "                            TTY = snomedTerm[4]\n",
    "                            outputSCTmatch = DataStructureOutputSCTmatch()\n",
    "                            \n",
    "                            if TTY == \"FN\":    \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                            elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                            else:      \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                            \n",
    "                            outputSCTmatch.y = snomedTerm[0]  \n",
    "                            outputSCTmatch.CODESCT = snomedTerm[1]     \n",
    "                            outputSCTmatch.STR = snomedTerm[2]            \n",
    "                            outputSCTmatch.matchedCUI = snomedTerm[3] +\"+\"+rSY[2]   \n",
    "                            outputSCTmatch.TTY = snomedTerm[4] \n",
    "                            outputSCTmatch.ISPREF = snomedTerm[5]    \n",
    "                            outputSCTmatch.STT = snomedTerm[6] #talvez deletar    \n",
    "                            outputSCTmatch.RELA = \"SY\"\n",
    "                            outputSCTmatch.regraSCT = \"CASO 4\" \n",
    "                            \n",
    "                            UMLSmatch.SCTmatches.append(outputSCTmatch)\n",
    "                            \n",
    "                            codigosSCT.append(snomedTerm)\n",
    "                elif rSY[2] == CUIumls:\n",
    "                    for snomedTerm in snomed:\n",
    "                        if snomedTerm[3] == rSY[1] and snomedTerm not in codigosSCT:\n",
    "                            TTY = snomedTerm[4]\n",
    "                            outputSCTmatch = DataStructureOutputSCTmatch()\n",
    "                            \n",
    "                            if TTY == \"FN\":    \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().ativoEspecificado\n",
    "                            elif TTY == \"OF\" or TTY == \"OAS\" or TTY == \"OAP\" or TTY == \"IS\":       \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().obsoleto\n",
    "                            else:      \n",
    "                                outputSCTmatch.status = EstadoCodigoSCT().ativo\n",
    "                            \n",
    "                            outputSCTmatch.y = snomedTerm[0]  \n",
    "                            outputSCTmatch.CODESCT = snomedTerm[1]     \n",
    "                            outputSCTmatch.STR = snomedTerm[2]            \n",
    "                            outputSCTmatch.matchedCUI = snomedTerm[3] +\"+\"+rSY[1]   \n",
    "                            outputSCTmatch.TTY = snomedTerm[4] \n",
    "                            outputSCTmatch.ISPREF = snomedTerm[5]    \n",
    "                            outputSCTmatch.STT = snomedTerm[6] #talvez deletar    \n",
    "                            outputSCTmatch.RELA = \"SY\"\n",
    "                            outputSCTmatch.regraSCT = \"CASO 4\" \n",
    "                            \n",
    "                            UMLSmatch.SCTmatches.append(outputSCTmatch)\n",
    "                                \n",
    "                            codigosSCT.append(snomedTerm)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "\n",
    "    def existeConceitoAtivo(self,output):\n",
    "        for UMLSmatch in output.UMLSmatches:\n",
    "            for outputSCTmatch in UMLSmatch.SCTmatches:\n",
    "                if outputSCTmatch.status == EstadoCodigoSCT().ativoEspecificado or outputSCTmatch.status == EstadoCodigoSCT().ativo:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def mapToSNOMEDCT(self,texto,output,UMLStoSNOMEDdata,temposExecucao):\n",
    "        \n",
    "        if len(output.UMLSmatches) == 0:\n",
    "            return temposExecucao,output\n",
    "        \n",
    "        #MRCONSO -> y,CODE,STR,CUI,TTY,ISPREF,STT\n",
    "        #MRREL -> y,CUI1,CUI2,SAB,REL,RELA\n",
    "        snomed = UMLStoSNOMEDdata[0]\n",
    "        SY = UMLStoSNOMEDdata[1]\n",
    "        REL_SNOMED = UMLStoSNOMEDdata[2]\n",
    "        #REL_MTH = UMLStoSNOMEDdata[3]\n",
    "        \n",
    "        a = datetime.datetime.now()\n",
    "        encontrouCodigoSCT,output = self.buscaSCT(output,snomed)\n",
    "        b = datetime.datetime.now()\n",
    "        temposExecucao.BUSCA = b-a    \n",
    "            \n",
    "        if encontrouCodigoSCT: #se foi encontrado algum codigo SCT\n",
    "            a = datetime.datetime.now()\n",
    "            output = self.classificaStatus(output)\n",
    "            if self.existeConceitoAtivo(output):\n",
    "                output = self.caso12(output)\n",
    "                b = datetime.datetime.now()\n",
    "                temposExecucao.C12 = b-a   \n",
    "                return temposExecucao,output\n",
    "            else: #se todos os codigos são obsoletos\n",
    "                output = self.caso3(output,snomed,SY,REL_SNOMED)\n",
    "                #output pode não conter nenhum codigo ativo mesmo após caso3\n",
    "                b = datetime.datetime.now()\n",
    "                temposExecucao.C3 = b-a   \n",
    "                return temposExecucao,output\n",
    "            \n",
    "        else:\n",
    "            a = datetime.datetime.now()\n",
    "            #se não existe conceito SCT associado\n",
    "            output = self.caso4(output,snomed,SY)\n",
    "            b = datetime.datetime.now()\n",
    "            temposExecucao.C4 = b-a   \n",
    "            return temposExecucao,output\n",
    "        \n",
    "    def removeRepeticaoUMLS(self,output):\n",
    "        if len(output.UMLSmatches) < 2:\n",
    "            return output\n",
    "        i=0\n",
    "        for x in range(len(output.UMLSmatches)-1):\n",
    "            if output.UMLSmatches[i].CUI == output.UMLSmatches[i+1].CUI and output.UMLSmatches[i].processadoString == output.UMLSmatches[i+1].processadoString:\n",
    "                output.UMLSmatches.remove(output.UMLSmatches[i])\n",
    "                i=i-1\n",
    "            i=i+1\n",
    "        return output\n",
    "    \n",
    "    def maptree(self,termo,termoProcessado,arvoresUMLS,UMLStoSNOMEDdata,distanciaMaxima = 1,rules=[1,1,1,1,1,1]):\n",
    "        output = DataStructureOutputSearchTerm()\n",
    "        output.searchTerm = termo\n",
    "        temposExecucao = TemposExecucao()\n",
    "        temposExecucao,output = self.mapToUMLStree(termoProcessado,arvoresUMLS,distanciaMaxima,output,temposExecucao,rules=rules)\n",
    "        output = self.removeRepeticaoUMLS(output)\n",
    "        temposExecucao,output = self.mapToSNOMEDCT(termoProcessado,output,UMLStoSNOMEDdata,temposExecucao)\n",
    "        return temposExecucao,output\n",
    "\n",
    "\n",
    "\n",
    "def mapMain(termos,MRCONSOFILE,MRXW_PORFILE,MRRELFILE,rules=[1,1,1,1,1,1]):\n",
    "    #INICIALIZANDO\n",
    "    p = PreProcessamento.getInstance()\n",
    "    u = UMLSclass(p)\n",
    "    m = Map(p)\n",
    "    \n",
    "    processUmlsFirstTime(MRCONSOFILE,MRXW_PORFILE,MRRELFILE)\n",
    "    createBKtree()\n",
    "    createSCTfiles(MRCONSOFILE,MRRELFILE)\n",
    "    \n",
    "    BKtreeClass = OpenBKtreeClass.getInstance()\n",
    "    SCTfileClass = OpenSCTfilesClass.getInstance()\n",
    "    #Wall time: 50 s\n",
    "    \n",
    "    #MAPEANDO\n",
    "    resultados = []\n",
    "    temposExecucao = []\n",
    "    position = 0\n",
    "    print(len(termos),\"termos\")\n",
    "    for termo in termos:\n",
    "        print(str(position),end=\"\\r\")\n",
    "        position+=1\n",
    "        \n",
    "        termoProcessado = p.processaMAPCLIN(termo)\n",
    "        result = m.maptree(termo,termoProcessado,BKtreeClass.treesUMLS,SCTfileClass.UMLStoSNOMEDdata,distanciaMaxima = 1,rules=rules)\n",
    "        resultados.append(result[1])\n",
    "        temposExecucao.append(result[0])\n",
    "    #Wall time: 22min 26s      #para 600 termos      \n",
    "    return temposExecucao,resultados\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 18:51:15 INFO: Loading these models for language: pt (Portuguese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | bosque  |\n",
      "| mwt       | bosque  |\n",
      "| pos       | bosque  |\n",
      "| lemma     | bosque  |\n",
      "=======================\n",
      "\n",
      "2022-01-24 18:51:15 INFO: Use device: cpu\n",
      "2022-01-24 18:51:15 INFO: Loading: tokenize\n",
      "2022-01-24 18:51:15 INFO: Loading: mwt\n",
      "2022-01-24 18:51:15 INFO: Loading: pos\n",
      "2022-01-24 18:51:17 INFO: Loading: lemma\n",
      "2022-01-24 18:51:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrindo arvore UMLS\n",
      "Abrindo arquivos SCT\n",
      "28 termos\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#abre arquivos\n",
    "termos = [\"Cesáreas\",\"Paciente\",\"Edema\",\"Tacrolimo\",\"eletrocardiograma\",\"Retorno\",\"Curativo\",\"Seco\",\"Hemodiálise\",\n",
    "          \"respiraçao espontanea\",\"dreno de suctor\",\"repouso no leito\",\"debito hematico\",\"debito sanguinolento\",\n",
    "          \"acesso venoso periferico\",\"amarelo citrico\",\"incisao cirurgica abdominal\",\"evoluçao\",\"dia\",\"centro cirúrgico\"\n",
    "          ,\"acordado\",\"responsivo\",\"esquerda\",\"dreno\",\"torax\",\"membro superior direito\",\"salinizado\",\"diurese\"]\n",
    "\n",
    "#Voce deve ter ou os arquivos da UMLS, ou os arquivos ja processados no mesmo diretorio\n",
    "MRCONSOFILE = r\"C:\\Users\\joaov\\JupyterNotebook\\Clinimap_arquivos\\2021AA-full\\2021AA\\META\\MRCONSO.RRF\"\n",
    "MRXW_PORFILE = r\"C:\\Users\\joaov\\JupyterNotebook\\Clinimap_arquivos\\2021AA-full\\2021AA\\META\\MRXW_POR.RRF\"\n",
    "MRRELFILE = r\"C:\\Users\\joaov\\JupyterNotebook\\Clinimap_arquivos\\2021AA-full\\2021AA\\META\\MRREL.RRF\"\n",
    "\n",
    "rules=[1,1,1,1,1,1]\n",
    "\n",
    "temposExecucao,resultados = mapMain(termos,MRCONSOFILE,MRXW_PORFILE,MRRELFILE,rules=rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termo Buscado: Paciente\n",
      "Possui relação com codigo UMLS:\n",
      "\tCUI: C0030705\n",
      "\tTermo UMLS: Paciente\n",
      "\tObtido com: REGRA DIRETA\n",
      "\tDistancia: 0\n",
      "\tPossui relação com codigo SCT:\n",
      "\t\tCodigo: 116154003\n",
      "\t\tTermo SCT: Patient\n",
      "\t\tStatus: B-Conceito Ativo pois possui TTY:PT\n",
      "\t\tPreferência: Y\n",
      "\t\tMatch com CUI: C0030705\n",
      "\t\tObtido com: CASO12\n",
      "\tPossui relação com codigo SCT:\n",
      "\t\tCodigo: 116154003\n",
      "\t\tTermo SCT: Patient (person)\n",
      "\t\tStatus: A-Conceito Ativo e Totalmente Especificado pois possui TTY:FN\n",
      "\t\tPreferência: Y\n",
      "\t\tMatch com CUI: C0030705\n",
      "\t\tObtido com: CASO12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultados[1].toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termo Buscado</th>\n",
       "      <th>CUI</th>\n",
       "      <th>Termo UMLS</th>\n",
       "      <th>Regra UMLS</th>\n",
       "      <th>Distancia Levenshtein</th>\n",
       "      <th>Codigo SCT</th>\n",
       "      <th>Termo SCT</th>\n",
       "      <th>Estado SCT</th>\n",
       "      <th>Preferencia SCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paciente</td>\n",
       "      <td>C0030705</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>116154003</td>\n",
       "      <td>Patient (person)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paciente</td>\n",
       "      <td>C0030705</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>116154003</td>\n",
       "      <td>Patient</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Termo Buscado       CUI Termo UMLS    Regra UMLS Distancia Levenshtein  \\\n",
       "1      Paciente  C0030705   Paciente  REGRA DIRETA                     0   \n",
       "0      Paciente  C0030705   Paciente  REGRA DIRETA                     0   \n",
       "\n",
       "  Codigo SCT         Termo SCT                                  Estado SCT  \\\n",
       "1  116154003  Patient (person)  A-Conceito Ativo e Totalmente Especificado   \n",
       "0  116154003           Patient                            B-Conceito Ativo   \n",
       "\n",
       "  Preferencia SCT  \n",
       "1               Y  \n",
       "0               Y  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[1].toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termo Buscado</th>\n",
       "      <th>CUI</th>\n",
       "      <th>Termo UMLS</th>\n",
       "      <th>Regra UMLS</th>\n",
       "      <th>Distancia Levenshtein</th>\n",
       "      <th>Codigo SCT</th>\n",
       "      <th>Termo SCT</th>\n",
       "      <th>Estado SCT</th>\n",
       "      <th>Preferencia SCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>Cesarean section (procedure)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>149981006</td>\n",
       "      <td>Caesarean section (procedure)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>Caesarean section</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>CS - Cesarean section</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>CS - Caesarean section</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>Cesarean section</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267358000</td>\n",
       "      <td>Caesarean section NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156251002</td>\n",
       "      <td>Section - caesarean</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Cesarian section delivery</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Caesarian section delivery</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>149981006</td>\n",
       "      <td>Cesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Caesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156251002</td>\n",
       "      <td>Cesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>Cesarean section, NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156251002</td>\n",
       "      <td>Caesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>149981006</td>\n",
       "      <td>Caesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156259000</td>\n",
       "      <td>Cesarean section NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>11466000</td>\n",
       "      <td>Caesarean section, NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267358000</td>\n",
       "      <td>Cesarean section NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156259000</td>\n",
       "      <td>Caesarean section NOS</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Section - caesarean</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Section - cesarean</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>156251002</td>\n",
       "      <td>Section - cesarean</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cesáreas</td>\n",
       "      <td>C0007876</td>\n",
       "      <td>Cesárea</td>\n",
       "      <td>REGRA FILHO</td>\n",
       "      <td>1</td>\n",
       "      <td>267352004</td>\n",
       "      <td>Cesarean section</td>\n",
       "      <td>C-Conceito Obsoleto</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Paciente</td>\n",
       "      <td>C0030705</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>116154003</td>\n",
       "      <td>Patient (person)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Paciente</td>\n",
       "      <td>C0030705</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>116154003</td>\n",
       "      <td>Patient</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C1717255</td>\n",
       "      <td>Edema</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>267038008</td>\n",
       "      <td>Edema (finding)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Edema (morphologic abnormality)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>20741006</td>\n",
       "      <td>Hydrops (morphologic abnormality)</td>\n",
       "      <td>A-Conceito Ativo e Totalmente Especificado</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Oedematous</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>161988006</td>\n",
       "      <td>Edema NOS (finding)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>139250008</td>\n",
       "      <td>Oedema NOS (finding)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>158244000</td>\n",
       "      <td>[D]Dropsy (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>267038008</td>\n",
       "      <td>Oedema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>206888002</td>\n",
       "      <td>[D]Edema (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>158241008</td>\n",
       "      <td>[D]Oedema (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>158247007</td>\n",
       "      <td>[D]Oedema NOS (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>267038008</td>\n",
       "      <td>Edema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Edema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Oedema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>206894005</td>\n",
       "      <td>[D]Edema NOS (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>206891002</td>\n",
       "      <td>[D]Dropsy (situation)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>423666004</td>\n",
       "      <td>Edema (observable entity)</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>20741006</td>\n",
       "      <td>Dropsy</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>20741006</td>\n",
       "      <td>Hydrops</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>267038008</td>\n",
       "      <td>Interstitial oedema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Edematous</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>267038008</td>\n",
       "      <td>Interstitial edema</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Edema</td>\n",
       "      <td>C0013604</td>\n",
       "      <td>EDEMA</td>\n",
       "      <td>REGRA DIRETA</td>\n",
       "      <td>0</td>\n",
       "      <td>79654002</td>\n",
       "      <td>Oedema - lesion</td>\n",
       "      <td>B-Conceito Ativo</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Termo Buscado       CUI Termo UMLS    Regra UMLS Distancia Levenshtein  \\\n",
       "0       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "1       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "2       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "3       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "4       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "5       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "6       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "7       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "8       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "9       Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "10      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "11      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "12      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "13      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "14      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "15      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "16      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "17      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "18      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "19      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "20      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "21      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "22      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "23      Cesáreas  C0007876    Cesárea   REGRA FILHO                     1   \n",
       "24      Paciente  C0030705   Paciente  REGRA DIRETA                     0   \n",
       "25      Paciente  C0030705   Paciente  REGRA DIRETA                     0   \n",
       "26         Edema  C1717255      Edema  REGRA DIRETA                     0   \n",
       "27         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "28         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "29         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "30         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "31         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "32         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "33         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "34         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "35         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "36         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "37         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "38         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "39         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "40         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "41         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "42         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "43         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "44         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "45         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "46         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "47         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "48         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "49         Edema  C0013604      EDEMA  REGRA DIRETA                     0   \n",
       "\n",
       "   Codigo SCT                          Termo SCT  \\\n",
       "0    11466000       Cesarean section (procedure)   \n",
       "1   149981006      Caesarean section (procedure)   \n",
       "2    11466000                  Caesarean section   \n",
       "3    11466000              CS - Cesarean section   \n",
       "4    11466000             CS - Caesarean section   \n",
       "5    11466000                   Cesarean section   \n",
       "6   267358000              Caesarean section NOS   \n",
       "7   156251002                Section - caesarean   \n",
       "8   267352004          Cesarian section delivery   \n",
       "9   267352004         Caesarian section delivery   \n",
       "10  149981006                   Cesarean section   \n",
       "11  267352004                  Caesarean section   \n",
       "12  156251002                   Cesarean section   \n",
       "13   11466000              Cesarean section, NOS   \n",
       "14  156251002                  Caesarean section   \n",
       "15  149981006                  Caesarean section   \n",
       "16  156259000               Cesarean section NOS   \n",
       "17   11466000             Caesarean section, NOS   \n",
       "18  267358000               Cesarean section NOS   \n",
       "19  156259000              Caesarean section NOS   \n",
       "20  267352004                Section - caesarean   \n",
       "21  267352004                 Section - cesarean   \n",
       "22  156251002                 Section - cesarean   \n",
       "23  267352004                   Cesarean section   \n",
       "24  116154003                   Patient (person)   \n",
       "25  116154003                            Patient   \n",
       "26                                                 \n",
       "27  267038008                    Edema (finding)   \n",
       "28   79654002    Edema (morphologic abnormality)   \n",
       "29   20741006  Hydrops (morphologic abnormality)   \n",
       "30   79654002                         Oedematous   \n",
       "31  161988006                Edema NOS (finding)   \n",
       "32  139250008               Oedema NOS (finding)   \n",
       "33  158244000              [D]Dropsy (situation)   \n",
       "34  267038008                             Oedema   \n",
       "35  206888002               [D]Edema (situation)   \n",
       "36  158241008              [D]Oedema (situation)   \n",
       "37  158247007          [D]Oedema NOS (situation)   \n",
       "38  267038008                              Edema   \n",
       "39   79654002                              Edema   \n",
       "40   79654002                             Oedema   \n",
       "41  206894005           [D]Edema NOS (situation)   \n",
       "42  206891002              [D]Dropsy (situation)   \n",
       "43  423666004          Edema (observable entity)   \n",
       "44   20741006                             Dropsy   \n",
       "45   20741006                            Hydrops   \n",
       "46  267038008                Interstitial oedema   \n",
       "47   79654002                          Edematous   \n",
       "48  267038008                 Interstitial edema   \n",
       "49   79654002                    Oedema - lesion   \n",
       "\n",
       "                                    Estado SCT Preferencia SCT  \n",
       "0   A-Conceito Ativo e Totalmente Especificado               Y  \n",
       "1                             B-Conceito Ativo               Y  \n",
       "2                             B-Conceito Ativo               Y  \n",
       "3                             B-Conceito Ativo               Y  \n",
       "4                             B-Conceito Ativo               Y  \n",
       "5                             B-Conceito Ativo               N  \n",
       "6                          C-Conceito Obsoleto               Y  \n",
       "7                          C-Conceito Obsoleto               Y  \n",
       "8                          C-Conceito Obsoleto               Y  \n",
       "9                          C-Conceito Obsoleto               Y  \n",
       "10                         C-Conceito Obsoleto               N  \n",
       "11                         C-Conceito Obsoleto               N  \n",
       "12                         C-Conceito Obsoleto               N  \n",
       "13                         C-Conceito Obsoleto               N  \n",
       "14                         C-Conceito Obsoleto               N  \n",
       "15                         C-Conceito Obsoleto               N  \n",
       "16                         C-Conceito Obsoleto               N  \n",
       "17                         C-Conceito Obsoleto               N  \n",
       "18                         C-Conceito Obsoleto               N  \n",
       "19                         C-Conceito Obsoleto               N  \n",
       "20                         C-Conceito Obsoleto               N  \n",
       "21                         C-Conceito Obsoleto               N  \n",
       "22                         C-Conceito Obsoleto               Y  \n",
       "23                         C-Conceito Obsoleto               N  \n",
       "24  A-Conceito Ativo e Totalmente Especificado               Y  \n",
       "25                            B-Conceito Ativo               Y  \n",
       "26                                                              \n",
       "27  A-Conceito Ativo e Totalmente Especificado               Y  \n",
       "28  A-Conceito Ativo e Totalmente Especificado               Y  \n",
       "29  A-Conceito Ativo e Totalmente Especificado               Y  \n",
       "30                            B-Conceito Ativo               Y  \n",
       "31                            B-Conceito Ativo               Y  \n",
       "32                            B-Conceito Ativo               Y  \n",
       "33                            B-Conceito Ativo               Y  \n",
       "34                            B-Conceito Ativo               Y  \n",
       "35                            B-Conceito Ativo               Y  \n",
       "36                            B-Conceito Ativo               Y  \n",
       "37                            B-Conceito Ativo               Y  \n",
       "38                            B-Conceito Ativo               N  \n",
       "39                            B-Conceito Ativo               N  \n",
       "40                            B-Conceito Ativo               N  \n",
       "41                            B-Conceito Ativo               Y  \n",
       "42                            B-Conceito Ativo               N  \n",
       "43                            B-Conceito Ativo               Y  \n",
       "44                            B-Conceito Ativo               N  \n",
       "45                            B-Conceito Ativo               N  \n",
       "46                            B-Conceito Ativo               Y  \n",
       "47                            B-Conceito Ativo               Y  \n",
       "48                            B-Conceito Ativo               Y  \n",
       "49                            B-Conceito Ativo               Y  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outFileName = \"outputMapClin2TermosOriginais.csv\"\n",
    "\n",
    "pandasDF = []\n",
    "for resultado in resultados:\n",
    "    pandasDF.append(resultado.toPandas())\n",
    "df = pd.concat(pandasDF)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#df.to_csv(outFileName) #SALVA\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R1': 17571.928571428572,\n",
       " 'R2': 8170.526315789473,\n",
       " 'R3': 32.78947368421053,\n",
       " 'R4': 42541.94736842105,\n",
       " 'R5': 23153.947368421053,\n",
       " 'R6': 18634.0,\n",
       " 'R7': 0,\n",
       " 'BUSCA': 2650.7,\n",
       " 'C12': 0.0,\n",
       " 'C3': 316152.0,\n",
       " 'C4': 313225.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(temposExecucao[0].criaEstatistica(temposExecucao)[1])\n",
    "#media #microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R1': 28,\n",
       " 'R2': 19,\n",
       " 'R3': 19,\n",
       " 'R4': 19,\n",
       " 'R5': 19,\n",
       " 'R6': 19,\n",
       " 'R7': 0,\n",
       " 'BUSCA': 20,\n",
       " 'C12': 17,\n",
       " 'C3': 1,\n",
       " 'C4': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(temposExecucao[0].criaEstatistica(temposExecucao)[0])\n",
    "#quantidade de chamadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
